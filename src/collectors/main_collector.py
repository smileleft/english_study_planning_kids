"""ë©”ì¸ ìˆ˜ì§‘ orchestrator"""

import logging
import time
from typing import List, Dict, Set
from datetime import datetime

from .youtube_collector import YouTubeCollector
from .content_analyzer import ContentAnalyzer
from ..models.video_model import VideoData
from ..models.channel_model import ChannelData
from config.keywords import SEARCH_KEYWORDS

class MainCollector:
    def __init__(self, api_key: str, min_quality_score: int = 50):
        self.youtube_collector = YouTubeCollector(api_key)
        self.content_analyzer = ContentAnalyzer()
        self.min_quality_score = min_quality_score
        self.logger = logging.getLogger(__name__)
        
        # ìˆ˜ì§‘ í†µê³„
        self.stats = {
            'total_searched': 0,
            'total_analyzed': 0,
            'high_quality_videos': 0,
            'channels_discovered': 0
        }
    
    def collect_oxford_reading_tree_level1(self) -> Dict[str, any]:
        """Oxford Reading Tree Level 1 ì½˜í…ì¸  ì „ì²´ ìˆ˜ì§‘ í”„ë¡œì„¸ìŠ¤"""
        
        self.logger.info("ğŸ¯ Oxford Reading Tree Level 1 ì½˜í…ì¸  ìˆ˜ì§‘ ì‹œì‘")
        start_time = datetime.now()
        
        all_videos = []
        channel_stats = {}
        
        # 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ìƒ ê²€ìƒ‰
        self.logger.info("ğŸ“‹ 1ë‹¨ê³„: í‚¤ì›Œë“œ ê¸°ë°˜ ì˜ìƒ ê²€ìƒ‰")
        
        for i, keyword in enumerate(SEARCH_KEYWORDS, 1):
            self.logger.info(f"  ({i}/{len(SEARCH_KEYWORDS)}) ê²€ìƒ‰: '{keyword}'")
            
            videos = self.youtube_collector.search_videos(keyword, max_results=25)
            self.stats['total_searched'] += len(videos)
            
            # ê° ì˜ìƒ í’ˆì§ˆ ë¶„ì„
            for video in videos:
                quality_score = self.content_analyzer.calculate_quality_score(video)
                video.quality_score = quality_score
                video.is_level1_content = self.content_analyzer.is_level1_content(video)
                video.learning_objectives = self.content_analyzer.extract_learning_objectives(video)
                
                self.stats['total_analyzed'] += 1
                
                # ê³ í’ˆì§ˆ ì˜ìƒë§Œ ìˆ˜ì§‘
                if quality_score >= self.min_quality_score:
                    all_videos.append(video)
                    self.stats['high_quality_videos'] += 1
                    
                    # ì±„ë„ í†µê³„ ì—…ë°ì´íŠ¸
                    self._update_channel_stats(channel_stats, video)
            
            # API ì œí•œ ì¤€ìˆ˜
            time.sleep(1)
        
        # 2ë‹¨ê³„: ê³ í’ˆì§ˆ ì±„ë„ì—ì„œ ì¶”ê°€ ìˆ˜ì§‘
        self.logger.info("ğŸ† 2ë‹¨ê³„: ê³ í’ˆì§ˆ ì±„ë„ì—ì„œ ì¶”ê°€ ìˆ˜ì§‘")
        
        high_quality_channels = self._identify_high_quality_channels(channel_stats)
        
        for channel_id, channel_info in high_quality_channels.items():
            self.logger.info(f"  ì¶”ê°€ ìˆ˜ì§‘: {channel_info['name']}")
            
            additional_videos = self.youtube_collector.get_channel_videos(channel_id, max_results=15)
            
            for video in additional_videos:
                quality_score = self.content_analyzer.calculate_quality_score(video)
                video.quality_score = quality_score
                video.is_level1_content = self.content_analyzer.is_level1_content(video)
                video.learning_objectives = self.content_analyzer.extract_learning_objectives(video)
                
                if quality_score >= self.min_quality_score:
                    all_videos.append(video)
                    self.stats['high_quality_videos'] += 1
            
            time.sleep(2)  # ì±„ë„ë³„ ëŒ€ê¸°
        
        # 3ë‹¨ê³„: ë°ì´í„° ì •ì œ ë° ì •ë ¬
        self.logger.info("ğŸ”§ 3ë‹¨ê³„: ë°ì´í„° ì •ì œ ë° ì •ë ¬")
        
        # ì¤‘ë³µ ì œê±°
        unique_videos = self._remove_duplicates(all_videos)
        
        # í’ˆì§ˆ ì ìˆ˜ë¡œ ì •ë ¬
        sorted_videos = sorted(unique_videos, key=lambda x: x.quality_score, reverse=True)
        
        # ìµœì¢… í†µê³„
        end_time = datetime.now()
        duration = end_time - start_time
        
        self.logger.info(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ!")
        self.logger.info(f"  - ì†Œìš” ì‹œê°„: {duration}")
        self.logger.info(f"  - ê²€ìƒ‰ëœ ì˜ìƒ: {self.stats['total_searched']}ê°œ")
        self.logger.info(f"  - ë¶„ì„ëœ ì˜ìƒ: {self.stats['total_analyzed']}ê°œ") 
        self.logger.info(f"  - ê³ í’ˆì§ˆ ì˜ìƒ: {len(sorted_videos)}ê°œ")
        self.logger.info(f"  - ë°œê²¬ëœ ì±„ë„: {len(channel_stats)}ê°œ")
        
        return {
            'videos': sorted_videos,
            'channel_stats': channel_stats,
            'collection_stats': self.stats,
            'collection_time': duration,
            'timestamp': end_time
        }
    
    def _update_channel_stats(self, channel_stats: Dict, video: VideoData):
        """ì±„ë„ í†µê³„ ì—…ë°ì´íŠ¸"""
        channel_id = video.channel_id
        
        if channel_id not in channel_stats:
            channel_stats[channel_id] = {
                'name': video.channel_title,
                'video_count': 0,
                'total_quality_score': 0,
                'videos': [],
                'avg_quality_score': 0
            }
        
        stats = channel_stats[channel_id]
        stats['video_count'] += 1
        stats['total_quality_score'] += video.quality_score
        stats['avg_quality_score'] = stats['total_quality_score'] / stats['video_count']
        stats['videos'].append(video)
    
    def _identify_high_quality_channels(self, channel_stats: Dict) -> Dict:
        """ê³ í’ˆì§ˆ ì±„ë„ ì‹ë³„"""
        high_quality_channels = {}
        
        for channel_id, stats in channel_stats.items():
            # ê³ í’ˆì§ˆ ì±„ë„ ê¸°ì¤€:
            # 1. 2ê°œ ì´ìƒì˜ ê³ í’ˆì§ˆ ì˜ìƒ
            # 2. í‰ê·  í’ˆì§ˆ ì ìˆ˜ 70ì  ì´ìƒ
            if (stats['video_count'] >= 2 and 
                stats['avg_quality_score'] >= 70):
                
                high_quality_channels[channel_id] = stats
        
        # ìƒìœ„ 5ê°œ ì±„ë„ë§Œ ì¶”ê°€ ìˆ˜ì§‘
        sorted_channels = sorted(
            high_quality_channels.items(),
            key=lambda x: x[1]['avg_quality_score'],
            reverse=True
        )
        
        return dict(sorted_channels[:5])
    
    def _remove_duplicates(self, videos: List[VideoData]) -> List[VideoData]:
        """ì¤‘ë³µ ì˜ìƒ ì œê±°"""
        seen_ids = set()
        unique_videos = []
        
        for video in videos:
            if video.video_id not in seen_ids:
                seen_ids.add(video.video_id)
                unique_videos.append(video)
        
        removed_count = len(videos) - len(unique_videos)
        if removed_count > 0:
            self.logger.info(f"  ì¤‘ë³µ ì œê±°: {removed_count}ê°œ ì˜ìƒ")
        
        return unique_videos

